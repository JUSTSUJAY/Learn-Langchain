{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d6bc7bd",
   "metadata": {},
   "source": [
    "Large Language Models, while recognized for creating human-like text, can also \"hallucinate\" and produce seemingly plausible yet incorrect or nonsensical information. Interestingly, this tendency can be advantageous in creative tasks, as it generates a range of unique and imaginative ideas, sparking new perspectives and driving the creative process. However, this poses a challenge in situations where accuracy is critical, such as code reviews, insurance-related tasks, or research question responses.\n",
    "\n",
    "One approach to mitigating hallucination is to provide documents as sources of information to the LLM and ask it to generate an answer based on the knowledge extracted from the document. This can help reduce the likelihood of hallucination, and users can verify the information with the source document.\n",
    "\n",
    "Let's discuss the pros and cons of this approach:\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "- Reduced hallucination: By providing a source document, the LLM is more likely to generate content based on the given information, reducing the chances of creating false or irrelevant information.\n",
    "- Increased accuracy: With a reliable source document, the LLM can generate more accurate answers, especially in use cases where accuracy is crucial.\n",
    "- Verifiable information: Users can cross-check the generated content with the source document to ensure the information is accurate and reliable.\n",
    "\n",
    "**Cons**:\n",
    "\n",
    "- Limited scope: Relying on a single document may limit the scope of the generated content, as the LLM will only have access to the information provided in the document.\n",
    "- Dependence on document quality: The accuracy of the generated content heavily depends on the quality and reliability of the source document. The LLM will likely generate incorrect or misleading content if the document contains inaccurate or biased information.\n",
    "- Inability to eliminate hallucination completely: Although providing a document as a base reduces the chances of hallucination, it does not guarantee that the LLM will never generate false or irrelevant information.\n",
    "\n",
    "Addressing another challenge, LLMs have a maximum prompt size, preventing them from feeding entire documents. This makes it crucial to divide documents into smaller parts, and Text Splitters prove to be extremely useful in achieving this. Text Splitters help break down large text documents into smaller, more digestible pieces that language models can process more effectively.\n",
    "\n",
    "Using a Text Splitter can also improve vector store search results, as smaller segments might be more likely to match a query. Experimenting with different chunk sizes and overlaps can be beneficial in tailoring results to suit your specific needs.\n",
    "\n",
    "**Customizing Text Splitter**\n",
    "\n",
    "When handling lengthy pieces of text, it's crucial to break them down into manageable chunks. This seemingly simple task can quickly become complex, as keeping semantically related text segments intact is essential. The definition of \"semantically related\" may vary depending on the type of text. In this article, we'll explore various strategies to achieve this.\n",
    "\n",
    "At a high level, text splitters follow these steps:\n",
    "\n",
    "Divide the text into small, semantically meaningful chunks (often sentences).\n",
    "Combine these small chunks into a larger one until a specific size is reached (determined by a particular function).\n",
    "Once the desired size is attained, separate that chunk as an individual piece of text, then start forming a new chunk with some overlap to maintain context between segments.\n",
    "Consequently, there are two primary dimensions to consider when customizing your text splitter:\n",
    "\n",
    "The method used to split the text\n",
    "The approach for measuring chunk size\n",
    "\n",
    "**Character Text Splitter**\n",
    "\n",
    "This type of splitter can be used in various scenarios where you must split long text pieces into smaller, semantically meaningful chunks. For example, you might use it to split a long article into smaller chunks for easier processing or analysis. The splitter allows you to customize the chunking process along two axes - chunk size and chunk overlap - to balance the trade-offs between splitting the text into manageable pieces and preserving semantic context between chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "557b0de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.7.3) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"Linux manual.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e470c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='THE ONE     PAGE LINUX MANUALA summary of useful Linux commands\\nVersion 3.0 May 1999 squadron@powerup.com.au\\nStarting & Stopping\\nshutdown -h now Shutdown the system now and do not\\nreboot\\nhalt Stop all processes - same as above\\nshutdown -r 5 Shutdown the system in 5 minutes and\\nreboot\\nshutdown -r now Shutdown the system now and reboot\\nreboot Stop all processes and then reboot - same\\nas above\\nstartx Start the X system\\nAccessing & mounting file systems\\nmount -t iso9660 /dev/cdrom\\n/mnt/cdromMount the device cdrom\\nand call it cdrom under the\\n/mnt directory\\nmount -t msdos /dev/hdd\\n/mnt/ddriveMount hard disk “d” as a\\nmsdos file system and call\\nit ddrive under the /mnt\\ndirectory\\nmount -t vfat /dev/hda1\\n/mnt/cdriveMount hard disk “a” as a\\nVFAT file system and call it\\ncdrive under the /mnt\\ndirectory\\numount /mnt/cdrom Unmount the cdrom\\nFinding files and text within files\\nfind / -name  fname Starting with the root directory, look\\nfor the file called fname\\nfind / -name ”*fname* ” Starting with the root directory, look\\nfor the file containing the string fname\\nlocate missingfilename Find a file called missingfilename\\nusing the locate command - this\\nassumes you have already used the\\ncommand updatedb (see next)\\nupdatedb Create or update the database of files\\non all file systems attached to the linux\\nroot directory\\nwhich missingfilename Show the subdirectory containing the\\nexecutable file  called missingfilename\\ngrep textstringtofind\\n/dirStarting with the directory called dir ,\\nlook for and list all files containing\\ntextstringtofind\\nThe X Window System\\nxvidtune Run the X graphics tuning utility\\nXF86Setup Run the X configuration menu with\\nautomatic probing of graphics cards\\nXconfigurator Run another X configuration menu with\\nautomatic probing of graphics cards\\nxf86config Run a text based X configuration menu\\nMoving, copying, deleting & viewing files\\nls -l List files in current directory using\\nlong format\\nls -F List files in current directory and\\nindicate the file type\\nls -laC List all files in current directory in\\nlong format and display in columnsrm name Remove a file or directory called\\nname\\nrm -rf name Kill off an entire directory and all it’s\\nincludes files and subdirectories\\ncp filename\\n/home/dirnameCopy the file called filename to the\\n/home/dirname directory\\nmv filename\\n/home/dirnameMove the file called filename to the\\n/home/dirname directory\\ncat filetoview Display the file called filetoview\\nman -k keyword Display man pages containing\\nkeyword\\nmore filetoview Display the file called filetoview one\\npage at a time, proceed to next page\\nusing the spacebar\\nhead filetoview Display the first 10 lines of the file\\ncalled filetoview\\nhead -20 filetoview Display the first 20 lines of the file\\ncalled filetoview\\ntail filetoview Display the last 10 lines of the file\\ncalled filetoview\\ntail -20 filetoview Display the last 20 lines of the file\\ncalled filetoview\\nInstalling software for Linux\\nrpm -ihv name.rpm Install the rpm package called name\\nrpm -Uhv name.rpm Upgrade the rpm package called\\nname\\nrpm -e package Delete the rpm package called\\npackage\\nrpm -l package List the files in the package called\\npackage\\nrpm -ql package List the files and state the installed\\nversion of the package called\\npackage\\nrpm -i --force package Reinstall the rpm package called\\nname having deleted parts of it (not\\ndeleting using rpm -e)\\ntar -zxvf archive.tar.gz or\\ntar -zxvf archive.tgzDecompress the files contained in\\nthe zipped and tarred archive called\\narchive\\n./configure Execute the script preparing the\\ninstalled files for compiling\\nUser Administration\\nadduser accountname Create a new user call accountname\\npasswd accountname Give accountname a new password\\nsu Log in as superuser from current login\\nexit Stop being superuser and revert to\\nnormal user\\nLittle known tips and tricks\\nifconfig List ip addresses for all devices on\\nthe machine\\napropos subject List manual pages for subject\\nusermount Executes graphical application for\\nmounting and unmounting file\\nsystems' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "You have 2 documents\n",
      "\n",
      "Preview:\n",
      "THE ONE     PAGE LINUX MANUALA summary of useful Linux commands\n",
      "Version 3.0 May 1999 squadron@powerup.com.au\n",
      "Starting & Stopping\n",
      "shutdown -h now Shutdown the system now and do not\n",
      "reboot\n",
      "halt Stop all processes - same as above\n",
      "shutdown -r 5 Shutdown the system in 5 minutes and\n",
      "reboot\n",
      "shutdown -r now Shutdown the system now and reboot\n",
      "reboot Stop all processes and then reboot - same\n",
      "as above\n",
      "startx Start the X system\n",
      "Accessing & mounting file systems\n",
      "mount -t iso9660 /dev/cdrom\n",
      "/mnt/cdromMount the device cdrom\n",
      "and call it cdrom under the\n",
      "/mnt directory\n",
      "mount -t msdos /dev/hdd\n",
      "/mnt/ddriveMount hard disk “d” as a\n",
      "msdos file system and call\n",
      "it ddrive under the /mnt\n",
      "directory\n",
      "mount -t vfat /dev/hda1\n",
      "/mnt/cdriveMount hard disk “a” as a\n",
      "VFAT file system and call it\n",
      "cdrive under the /mnt\n",
      "directory\n",
      "umount /mnt/cdrom Unmount the cdrom\n",
      "Finding files and text within files\n",
      "find / -name  fname Starting with the root directory, look\n",
      "for the file called fname\n",
      "find / -name ”*fname* ” Starting with the root directory, look\n",
      "for the file containing the string fname\n",
      "locate missingfilename Find a file called missingfilename\n",
      "using the locate command - this\n",
      "assumes you have already used the\n",
      "command updatedb (see next)\n",
      "updatedb Create or update the database of files\n",
      "on all file systems attached to the linux\n",
      "root directory\n",
      "which missingfilename Show the subdirectory containing the\n",
      "executable file  called missingfilename\n",
      "grep textstringtofind\n",
      "/dirStarting with the directory called dir ,\n",
      "look for and list all files containing\n",
      "textstringtofind\n",
      "The X Window System\n",
      "xvidtune Run the X graphics tuning utility\n",
      "XF86Setup Run the X configuration menu with\n",
      "automatic probing of graphics cards\n",
      "Xconfigurator Run another X configuration menu with\n",
      "automatic probing of graphics cards\n",
      "xf86config Run a text based X configuration menu\n",
      "Moving, copying, deleting & viewing files\n",
      "ls -l List files in current directory using\n",
      "long format\n",
      "ls -F List files in current directory and\n",
      "indicate the file type\n",
      "ls -laC List all files in current directory in\n",
      "long format and display in columnsrm name Remove a file or directory called\n",
      "name\n",
      "rm -rf name Kill off an entire directory and all it’s\n",
      "includes files and subdirectories\n",
      "cp filename\n",
      "/home/dirnameCopy the file called filename to the\n",
      "/home/dirname directory\n",
      "mv filename\n",
      "/home/dirnameMove the file called filename to the\n",
      "/home/dirname directory\n",
      "cat filetoview Display the file called filetoview\n",
      "man -k keyword Display man pages containing\n",
      "keyword\n",
      "more filetoview Display the file called filetoview one\n",
      "page at a time, proceed to next page\n",
      "using the spacebar\n",
      "head filetoview Display the first 10 lines of the file\n",
      "called filetoview\n",
      "head -20 filetoview Display the first 20 lines of the file\n",
      "called filetoview\n",
      "tail filetoview Display the last 10 lines of the file\n",
      "called filetoview\n",
      "tail -20 filetoview Display the last 20 lines of the file\n",
      "called filetoview\n",
      "Installing software for Linux\n",
      "rpm -ihv name.rpm Install the rpm package called name\n",
      "rpm -Uhv name.rpm Upgrade the rpm package called\n",
      "name\n",
      "rpm -e package Delete the rpm package called\n",
      "package\n",
      "rpm -l package List the files in the package called\n",
      "package\n",
      "rpm -ql package List the files and state the installed\n",
      "version of the package called\n",
      "package\n",
      "rpm -i --force package Reinstall the rpm package called\n",
      "name having deleted parts of it (not\n",
      "deleting using rpm -e)\n",
      "tar -zxvf archive.tar.gz or\n",
      "tar -zxvf archive.tgzDecompress the files contained in\n",
      "the zipped and tarred archive called\n",
      "archive\n",
      "./configure Execute the script preparing the\n",
      "installed files for compiling\n",
      "User Administration\n",
      "adduser accountname Create a new user call accountname\n",
      "passwd accountname Give accountname a new password\n",
      "su Log in as superuser from current login\n",
      "exit Stop being superuser and revert to\n",
      "normal user\n",
      "Little known tips and tricks\n",
      "ifconfig List ip addresses for all devices on\n",
      "the machine\n",
      "apropos subject List manual pages for subject\n",
      "usermount Executes graphical application for\n",
      "mounting and unmounting file\n",
      "systems\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "texts = text_splitter.split_documents(pages)\n",
    "\n",
    "print(texts[0])\n",
    "\n",
    "print (f\"You have {len(texts)} documents\")\n",
    "print()\n",
    "print (\"Preview:\")\n",
    "print (texts[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7755c1ac",
   "metadata": {},
   "source": [
    "No universal approach for chunking text will fit all scenarios - what's effective for one case might not be suitable for another. Finding the best chunk size for your project means going through a few steps. First, clean up your data by getting rid of anything that's not needed, like HTML tags from websites. Then, pick a few different chunk sizes to test. The best size will depend on what kind of data you're working with and the model you're using.  Finally, test out how well each size works by running some queries and comparing the results. You might need to try a few different sizes before finding the best one. This process might take some time, but getting the best results from your project is worth it.\n",
    "\n",
    "Recursive Character Text Splitter\n",
    "The Recursive Character Text Splitter is a text splitter designed to split the text into chunks based on a list of characters provided. It attempts to split text using the characters from a list in order until the resulting chunks are small enough. By default, the list of characters used for splitting is [\"\\n\\n\", \"\\n\", \" \", \"], which tries to keep paragraphs, sentences, and words together as long as possible, as they are generally the most semantically related pieces of text. This means that the class first tries to split the text into two new-line characters. If the resulting chunks are still larger than the desired chunk size, it will then try to split the output by a single new-line character, followed by a space character, and so on, until the desired chunk size is achieved.\n",
    "\n",
    "To use the RecursiveCharacterTextSplitter, you can create an instance of it and provide the following parameters:\n",
    "\n",
    "`chunk_size` : The maximum size of the chunks, as measured by the length_function (default is 100).\n",
    "\n",
    "`chunk_overlap`: The maximum overlap between chunks to maintain continuity between them (default is 20).\n",
    "\n",
    "`length_function`: parameter is used to calculate the length of the chunks. By default, it is set to ``len``, which counts the number of characters in a chunk. However, you can also pass a token counter or any other function that calculates the length of a chunk based on your specific requirements.\n",
    "\n",
    "Using a token counter instead of the default len function can benefit specific scenarios, such as when working with language models with token limits. For example, OpenAI's GPT-3 has a token limit of 4096 tokens per request, so you might want to count tokens instead of characters to better manage and optimize your requests.\n",
    "\n",
    "Here's an example of how to use RecursiveCharacterTextSplitter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5b7697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='THE ONE     PAGE LINUX MANUALA summary of useful' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='of useful Linux commands' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='Version 3.0 May 1999 squadron@powerup.com.au' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='Starting & Stopping' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='shutdown -h now Shutdown the system now and do' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='and do not' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='reboot\\nhalt Stop all processes - same as above' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='shutdown -r 5 Shutdown the system in 5 minutes' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='5 minutes and' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='reboot' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='shutdown -r now Shutdown the system now and' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='now and reboot' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='reboot Stop all processes and then reboot - same' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='as above\\nstartx Start the X system' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='Accessing & mounting file systems' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='mount -t iso9660 /dev/cdrom' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='/mnt/cdromMount the device cdrom' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='and call it cdrom under the\\n/mnt directory' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='mount -t msdos /dev/hdd' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='/mnt/ddriveMount hard disk “d” as a' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='msdos file system and call' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='it ddrive under the /mnt\\ndirectory' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='directory\\nmount -t vfat /dev/hda1' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='/mnt/cdriveMount hard disk “a” as a' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='VFAT file system and call it' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='cdrive under the /mnt\\ndirectory' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='directory\\numount /mnt/cdrom Unmount the cdrom' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='Finding files and text within files' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='find / -name  fname Starting with the root' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='the root directory, look' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='for the file called fname' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='find / -name ”*fname* ” Starting with the root' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='the root directory, look' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='for the file containing the string fname' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='locate missingfilename Find a file called' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='called missingfilename' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='using the locate command - this' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='assumes you have already used the' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='command updatedb (see next)' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='updatedb Create or update the database of files' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='on all file systems attached to the linux' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='root directory' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='which missingfilename Show the subdirectory' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='containing the' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='executable file  called missingfilename' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='grep textstringtofind' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='/dirStarting with the directory called dir ,' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='look for and list all files containing' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='textstringtofind\\nThe X Window System' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='xvidtune Run the X graphics tuning utility' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='XF86Setup Run the X configuration menu with' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='automatic probing of graphics cards' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='Xconfigurator Run another X configuration menu' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='menu with' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='automatic probing of graphics cards' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='xf86config Run a text based X configuration menu' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='Moving, copying, deleting & viewing files' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='ls -l List files in current directory using' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='long format' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='ls -F List files in current directory and' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='indicate the file type' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='ls -laC List all files in current directory in' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='long format and display in columnsrm name Remove' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='Remove a file or directory called' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='name' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='rm -rf name Kill off an entire directory and all' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='and all it’s' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='includes files and subdirectories\\ncp filename' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='/home/dirnameCopy the file called filename to the' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='/home/dirname directory\\nmv filename' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='/home/dirnameMove the file called filename to the' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='/home/dirname directory' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='cat filetoview Display the file called filetoview' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='man -k keyword Display man pages containing' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='keyword' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='more filetoview Display the file called' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='called filetoview one' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='page at a time, proceed to next page' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='using the spacebar' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='head filetoview Display the first 10 lines of the' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='of the file' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='called filetoview' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='head -20 filetoview Display the first 20 lines of' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='lines of the file' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='called filetoview' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='tail filetoview Display the last 10 lines of the' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='of the file' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='called filetoview' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='tail -20 filetoview Display the last 20 lines of' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='lines of the file' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='called filetoview\\nInstalling software for Linux' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='rpm -ihv name.rpm Install the rpm package called' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='called name' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='rpm -Uhv name.rpm Upgrade the rpm package called' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='name\\nrpm -e package Delete the rpm package called' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='package' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='rpm -l package List the files in the package' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='package called' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='package' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='rpm -ql package List the files and state the' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='state the installed' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='version of the package called\\npackage' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='rpm -i --force package Reinstall the rpm package' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='package called' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='name having deleted parts of it (not' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='deleting using rpm -e)' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='tar -zxvf archive.tar.gz or' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='tar -zxvf archive.tgzDecompress the files' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='the files contained in' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='the zipped and tarred archive called\\narchive' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='./configure Execute the script preparing the' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='installed files for compiling\\nUser Administration' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='adduser accountname Create a new user call' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='user call accountname' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='passwd accountname Give accountname a new' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='a new password' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='su Log in as superuser from current login' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='exit Stop being superuser and revert to' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='normal user\\nLittle known tips and tricks' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='ifconfig List ip addresses for all devices on' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='the machine' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='apropos subject List manual pages for subject' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='usermount Executes graphical application for' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='mounting and unmounting file\\nsystems' metadata={'source': 'Linux manual.pdf', 'page': 0}\n",
      "page_content='/sbin/e2fsck hda5 Execute the filesystem check' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='check utility' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='on partition hda5' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='fdformat /dev/fd0H1440 Format the floppy disk in' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='disk in device fd0' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='tar -cMf /dev/fd0 Backup the contents of the' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='of the current' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='directory and subdirectories to' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='multiple floppy disks' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='tail -f /var/log/messages Display the last 10' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='last 10 lines of the system' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='log.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='cat /var/log/dmesg Display the file containing' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='the boot' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='time messages - useful for locating' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='problems. Alternatively, use the\\ndmesg  command.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='* wildcard - represents everything. eg.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='cp from/* to  will copy all files in the' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='from directory to the to directory' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='? Single character wildcard. eg.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='cp config.? /configs will copy all files' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='beginning with the name config. in' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='the current directory to the directory' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='named configs.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='[xyz] Choice of character wildcards. eg.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='ls [xyz]* will list all files in the current' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='directory starting with the letter x, y,\\nor z.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='linux single At the lilo prompt, start in single' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='in single user' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='mode. This is useful if you have' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='forgotten your password. Boot in' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='single user mode, then run the\\npasswd  command.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='ps List current processes' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='kill 123 Kill a specific process eg. kill 123' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='Configuration files and what they do' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='/etc/profile System wide environment variables' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='variables for' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='all users.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='/etc/fstab List of devices and their associated' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='mount' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='points. Edit this file to add cdroms, DOS' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='partitions and floppy drives at startup.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='/etc/motd Message of the day broadcast to all' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='to all users' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='at login.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='etc/rc.d/rc.local Bash script that is executed at' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='at the end of' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='login process. Similar to autoexec.bat in\\nDOS.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='/etc/HOSTNAME Conatins full hostname including' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='including domain.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='/etc/cron.* There are 4 directories that' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='that automatically' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='execute all scripts within the directory at' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='intervals of hour, day, week or month.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='/etc/hosts A list of all know host names and IP' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='addresses on the machine.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='/etc/httpd/conf Paramters for the Apache web' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='web server' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='/etc/inittab Specifies the run level that the' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='that the machine' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='should boot into.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='/etc/resolv.conf Defines IP addresses of DNS' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='of DNS servers.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='/etc/smb.conf Config file for the SAMBA server.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='server. Allows' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='file and print sharing with Microsoft\\nclients.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='clients.\\n/etc/X11/XF86Confi' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='gConfig file for X -Windows.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='~/.xinitrc Defines the windows manager loaded by' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='X. ~ refers to user’s home directory.File' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='permissions' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='If the command ls -l is given, a long list of' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='list of file names is' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='displayed. The first column in this list details' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='details the permissions' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='applying to the file. If a permission is missing' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='missing for a owner,' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='group of other, it is represented by - eg.  drwxr' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='drwxr -x—x' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='Read = 4\\nWrite = 2' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='Execute = 1File permissions are altered by giving' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='by giving the' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='chmod command and the appropriate' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='octal code for each user type. eg' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='chmod 7 6 4 filename will make the file' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='called filename R+W+X for the owner,' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='R+W for the group and R for others.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='chmod 7 5 5 Full permission for the owner, read' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='read and' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='execute access for the group and others.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='chmod +x filename Make the file called filename' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='filename executable' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='to all users.\\nX Shortcuts - (mainly for Redhat)' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='Control|Alt  + or - Increase or decrease the' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='the screen' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='resolution. eg. from 640x480 to\\n800x600' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='Alt | escape Display list of active windows' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='Shift|Control F8 Resize the selected window' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='Right click on desktop\\nbackgroundDisplay menu' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='Shift|Control Altr Refresh the screen' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='Shift|Control Altx Start an xterm session' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='Printing' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='/etc/rc.d/init.d/lpd start Start the print daemon' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='/etc/rc.d/init.d/lpd stop Stop the print daemon' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='/etc/rc.d/init.d/lpd' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='statusDisplay status of the print daemon' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='lpq Display jobs in print queue' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='lprm Remove jobs from queue\\nlpr Print a file' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='lpc Printer control tool' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='man subject | lpr Print the manual page called' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='called subject' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='as plain text' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='man -t subject | lpr Print the manual page called' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='called subject' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='as Postscript output' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='printtool Start X printer setup' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='setup interface~/.Xdefaults Define configuration' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='for some X -' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='applications. ~ refers to user’s home\\ndirectory.' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='Get your own Official Linux Pocket Protector -' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='- includes' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='handy command summary. Visit:' metadata={'source': 'Linux manual.pdf', 'page': 1}\n",
      "page_content='www.powerup.com.au/~squadron' metadata={'source': 'Linux manual.pdf', 'page': 1}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = PyPDFLoader(\"Linux manual.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(pages)\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1318287",
   "metadata": {},
   "source": [
    "We created an instance of the RecursiveCharacterTextSplitter class with the desired parameters. The default list of characters to split by is [\"\\n\\n\", \"\\n\", \" \", \"\"].\n",
    "\n",
    "The text is first split by two new-line characters (\\n\\n). Then, since the chunks are still larger than the desired chunk size (50), the class tries to split the output by a single new-line character (\\n).\n",
    "\n",
    "In this example, the text is loaded from a file, and the ``RecursiveCharacterTextSplitter`` is used to split it into chunks with a maximum size of 50 characters and an overlap of 10 characters. The output will be a list of documents containing the split text.\n",
    "\n",
    "To use a token counter, you can create a custom function that calculates the number of tokens in a given text and pass it as the ``length_function`` parameter. This will ensure that your text splitter calculates the length of chunks based on the number of tokens instead of the number of characters\n",
    "\n",
    "**. NLTK Text Splitter**\n",
    "\n",
    "The NLTKTextSplitter in LangChain is an implementation of a text splitter that uses the Natural Language Toolkit (NLTK) library to split text based on tokenizers. The goal is to split long texts into smaller chunks without breaking the structure of sentences and paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d0f28d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 328, which is longer than the specified 250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Google opens up its AI language model PaLM to challenge OpenAI and GPT-3\\nGoogle is offering developers access to one of its most advanced AI language models: PaLM.', 'The search giant is launching an API for PaLM alongside a number of AI enterprise tools\\nit says will help businesses \\x93generate text, images, code, videos, audio, and more from\\nsimple natural language prompts.\\x94\\n\\nPaLM is a large language model, or LLM, similar to the GPT series created by OpenAI or\\nMeta\\x92s LLaMA family of models.', 'Google first announced PaLM in April 2022.\\n\\nLike other LLMs,\\nPaLM is a flexible system that can potentially carry out all sorts of text generation and\\nediting tasks.', 'You could train PaLM to be a conversational chatbot like ChatGPT, for\\nexample, or you could use it for tasks like summarizing text or even writing code.', '(It\\x92s similar to features Google also announced today for its Workspace apps like Google\\nDocs and Gmail.)']\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "\n",
    "# Load a long document\n",
    "with open('my_file.txt', encoding= 'unicode_escape') as f:\n",
    "    sample_text = f.read()\n",
    "\n",
    "text_splitter = NLTKTextSplitter(chunk_size=250)\n",
    "texts = text_splitter.split_text(sample_text)\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a3d6e",
   "metadata": {},
   "source": [
    "**SpacyTextSplitter**\n",
    "\n",
    "The ``SpacyTextSplitter`` helps split large text documents into smaller chunks based on a specified size. This is useful for better management of large text inputs. It's important to note that the ``SpacyTextSplitter`` is an alternative to NLTK-based sentence splitting. You can create a ``SpacyTextSplitter`` object by specifying the ``chunk_size`` parameter, measured by a length function passed to it, which defaults to the number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa05d1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "Created a chunk of size 328, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google opens up its AI language model PaLM to challenge OpenAI and GPT-3\n",
      "\n",
      "\n",
      "Google is offering developers access to one of its most advanced AI language models: PaLM.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "\n",
    "# Load a long document\n",
    "with open('my_file.txt', encoding= 'unicode_escape') as f:\n",
    "    sample_text = f.read()\n",
    "\n",
    "# Instantiate the SpacyTextSplitter with the desired chunk size\n",
    "text_splitter = SpacyTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "\n",
    "# Split the text using SpacyTextSplitter\n",
    "texts = text_splitter.split_text(sample_text)\n",
    "\n",
    "# Print the first chunk\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f7801",
   "metadata": {},
   "source": [
    "**MarkdownTextSplitter**\n",
    "\n",
    "The ``MarkdownTextSplitter`` is designed to split text written using Markdown languages like **headers, code blocks, or dividers**. It is implemented as a simple subclass of RecursiveCharacterSplitter with Markdown-specific separators. By default, these separators are determined by the **Markdown syntax**, but they can be customized by providing a list of characters during the initialization of the MarkdownTextSplitter instance. The chunk size, which is initially set to the number of characters, is measured by the length function passed in. To customize the chunk size, provide an integer value when initializing an instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e34a0e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='# \\n\\n# Welcome to My Blog!', metadata={}), Document(page_content='## Introduction', metadata={}), Document(page_content='Hello everyone! My name is **John Doe** and I am a _software developer_. I specialize in Python,', metadata={}), Document(page_content='Java, and JavaScript.', metadata={}), Document(page_content=\"Here's a list of my favorite programming languages:\\n\\n1. Python\\n2. JavaScript\\n3. Java\", metadata={}), Document(page_content='You can check out some of my projects on [GitHub](https://github.com).', metadata={}), Document(page_content='## About this Blog', metadata={}), Document(page_content=\"In this blog, I will share my journey as a software developer. I'll post tutorials, my thoughts on\", metadata={}), Document(page_content='the latest technology trends, and occasional book reviews.', metadata={}), Document(page_content=\"Here's a small piece of Python code to say hello:\", metadata={}), Document(page_content='\\\\``` python\\ndef say_hello(name):\\n    print(f\"Hello, {name}!\")\\n\\nsay_hello(\"John\")\\n\\\\', metadata={}), Document(page_content='```\\n\\nStay tuned for more updates!', metadata={}), Document(page_content='## Contact Me', metadata={}), Document(page_content='Feel free to reach out to me on [Twitter](https://twitter.com) or send me an email at', metadata={}), Document(page_content='johndoe@email.com.', metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "\n",
    "markdown_text = \"\"\"\n",
    "# \n",
    "\n",
    "# Welcome to My Blog!\n",
    "\n",
    "## Introduction\n",
    "Hello everyone! My name is **John Doe** and I am a _software developer_. I specialize in Python, Java, and JavaScript.\n",
    "\n",
    "Here's a list of my favorite programming languages:\n",
    "\n",
    "1. Python\n",
    "2. JavaScript\n",
    "3. Java\n",
    "\n",
    "You can check out some of my projects on [GitHub](https://github.com).\n",
    "\n",
    "## About this Blog\n",
    "In this blog, I will share my journey as a software developer. I'll post tutorials, my thoughts on the latest technology trends, and occasional book reviews.\n",
    "\n",
    "Here's a small piece of Python code to say hello:\n",
    "\n",
    "\\``` python\n",
    "def say_hello(name):\n",
    "    print(f\"Hello, {name}!\")\n",
    "\n",
    "say_hello(\"John\")\n",
    "\\```\n",
    "\n",
    "Stay tuned for more updates!\n",
    "\n",
    "## Contact Me\n",
    "Feel free to reach out to me on [Twitter](https://twitter.com) or send me an email at johndoe@email.com.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "markdown_splitter = MarkdownTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "docs = markdown_splitter.create_documents([markdown_text])\n",
    "\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecee61e",
   "metadata": {},
   "source": [
    "The MarkdownTextSplitter offers a practical solution for dividing text while preserving the structure and meaning provided by Markdown formatting. By recognizing the Markdown syntax (e.g., headings, lists, and code blocks), you can intelligently divide the content based on its structure and hierarchy, resulting in more semantically coherent chunks. This splitter is especially valuable when managing extensive Markdown documents.\n",
    "\n",
    "\n",
    "\n",
    "**TokenTextSplitter**\n",
    "\n",
    "The main advantage of using TokenTextSplitter over other text splitters, like CharacterTextSplitter, is that it respects the token boundaries, ensuring that the chunks do not split tokens in the middle. This can be particularly helpful in maintaining the semantic integrity of the text when working with language models and embeddings.\n",
    "\n",
    "This type of splitter breaks down raw text strings into smaller pieces by initially converting the text into BPE (Byte Pair Encoding) tokens, and subsequently dividing these tokens into chunks. It then reassembles the tokens within each chunk back into text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb7f74fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google opens up its AI language model PaLM to challenge OpenAI and GPT-3\n",
      "Google is offering developers access to one of its most advanced AI language models: PaLM.\n",
      "The search giant is launching an API for PaLM alongside a number of AI enterprise tools\n",
      "it says will help businesses generate text, images, code, videos, audio, and more from\n",
      "simple natural language prompts.\n",
      "\n",
      "PaLM is a large language model, or LLM,\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "# Load a long document\n",
    "with open('my_file.txt', encoding= 'unicode_escape') as f:\n",
    "    sample_text = f.read()\n",
    "\n",
    "# Initialize the TokenTextSplitter with desired chunk size and overlap\n",
    "text_splitter = TokenTextSplitter(chunk_size=100, chunk_overlap=50)\n",
    "\n",
    "# Split into smaller chunks\n",
    "texts = text_splitter.split_text(sample_text)\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43893fb3",
   "metadata": {},
   "source": [
    "The chunk_size parameter sets the maximum number of BPE tokens in each chunk, while chunk_overlap defines the number of overlapping tokens between adjacent chunks. By modifying these parameters, you can fine-tune the granularity of the text chunks.\n",
    "\n",
    "One potential drawback of using TokenTextSplitter is that it may require additional computation when converting text to BPE tokens and back. If you need a faster and simpler text-splitting method, you might consider using CharacterTextSplitter, which directly splits the text based on character count, offering a more straightforward approach to text segmentation.\n",
    "\n",
    "Text splitters are essential for managing long text, improving language model processing efficiency, and enhancing vector store search results. Customizing text splitters involves selecting the splitting method and measuring chunk size. \n",
    "\n",
    "CharacterTextSplitter is an example that helps balance manageable pieces and semantic context preservation. Experimenting with different chunk sizes and overlaps tailor the results for specific use cases.\n",
    "\n",
    "RecursiveCharacterTextSplitter focuses on preserving semantic relationships while offering customizable chunk sizes and overlaps. \n",
    "\n",
    "NLTKTextSplitter utilizes the Natural Language Toolkit library for more accurate text segmentation. SpacyTextSplitter leverages the popular SpaCy library to split texts based on linguistic features. MarkdownTextSplitter is tailored for Markdown-formatted texts, ensuring content is split meaningfully according to the syntax. Lastly, TokenTextSplitter employs BPE tokens for splitting, offering a fine-grained approach to text segmentation.\n",
    "\n",
    "\n",
    "Conclusion\n",
    "Selecting the appropriate text splitter depends on the specific requirements and nature of the text you are working with, ensuring optimal results for your text processing tasks.\n",
    "\n",
    "In the next lesson, we’ll learn more about how word embeddings work and how embedding models are used with indexers in LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc78c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
