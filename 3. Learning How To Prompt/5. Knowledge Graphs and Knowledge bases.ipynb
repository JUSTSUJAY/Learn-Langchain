{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9bf3941",
   "metadata": {},
   "source": [
    "- used interchangably but there are subtle differences\n",
    "- KB - Structurred information that we have about the domain of interest\n",
    "- KG - it is KB structured as Graph - **nodes** = entities and **edges** - relations between entities\n",
    "- Lets take an example \n",
    "\n",
    "**Mahadev Lives on Kailash**\n",
    "- WE can break down this sentence into [Mahadev, Lives on, Kailash].<br><br>\n",
    "Where Mahadev and Kailash are Named entities and lives on signifies their relation\n",
    "\n",
    "\n",
    "## Building a Knowledge Graph\n",
    " - Step 1. NER(named entity recognition) - This entities will become the nodes of our graph\n",
    " - Step 2 - find the relationships between this entities - become edges\n",
    " \n",
    " As said earlier Knowledge graphs are nothing but knowledge bases so how do we create the knowledge bases\n",
    "  \n",
    " 1. Entity linking - normalizing the different entities to the same entity - Napolean = Napolean Bonapart\n",
    " 2. Source tracking - Keeping track of the origin of each relation, such as the article URL and text span. Keeping track of the sources allows us to gather insights into the reliability of the extracted information (e.g., a relation is accurate if it can be extracted from several sources considered accurate).\n",
    " \n",
    " we’ll do the Named Entity Recognition and Relation Classification tasks simultaneously with an appropriate prompt. This joint task is commonly called Relation Extraction (RE).\n",
    " \n",
    "## Building a Knowledge Graph with LangChain\n",
    "To demonstrate an example of using a prompt to extract relations from the text in LangChain, we can use the following  KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT prompt as a starting point. This prompt is designed to extract knowledge triples (subject, predicate, and object) from a given text input.\n",
    "\n",
    "This prompt can be used by the ConversationEntityMemory class from LangChain library, which is a way for chatbots to keep a memory of the past messages of a conversation by storing the relations extracted from the past messages. Memory classes will be explained in a later lesson. In this example, we use this prompt just to extract relations from texts without leveraging a memory class.\n",
    "\n",
    "Let's understand the structure of the KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT. This prompt is an instance of the PromptTemplate class with the input variable text. The template is a string that provides a few shot examples and instructions for the language model to follow when extracting knowledge triples from the input text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457ded97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyvis\n",
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.graphs.networkx_graph import KG_TRIPLE_DELIMITER\n",
    "\n",
    "# Prompt template for knowledge triple extraction\n",
    "_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE = (\n",
    "    \"You are a networked intelligence helping a human track knowledge triples\"\n",
    "    \" about all relevant people, things, concepts, etc. and integrating\"\n",
    "    \" them with your knowledge stored within your weights\"\n",
    "    \" as well as that stored in a knowledge graph.\"\n",
    "    \" Extract all of the knowledge triples from the text.\"\n",
    "    \" A knowledge triple is a clause that contains a subject, a predicate,\"\n",
    "    \" and an object. The subject is the entity being described,\"\n",
    "    \" the predicate is the property of the subject that is being\"\n",
    "    \" described, and the object is the value of the property.\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"It's a state in the US. It's also the number 1 producer of gold in the US.\\n\\n\"\n",
    "    f\"Output: (Nevada, is a, state){KG_TRIPLE_DELIMITER}(Nevada, is in, US)\"\n",
    "    f\"{KG_TRIPLE_DELIMITER}(Nevada, is the number 1 producer of, gold)\\n\"\n",
    "    \"END OF EXAMPLE\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"I'm going to the store.\\n\\n\"\n",
    "    \"Output: NONE\\n\"\n",
    "    \"END OF EXAMPLE\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"Oh huh. I know Descartes likes to drive antique scooters and play the mandolin.\\n\"\n",
    "    f\"Output: (Descartes, likes to drive, antique scooters){KG_TRIPLE_DELIMITER}(Descartes, plays, mandolin)\\n\"\n",
    "    \"END OF EXAMPLE\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"{text}\"\n",
    "    \"Output:\"\n",
    ")\n",
    "\n",
    "KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE,\n",
    ")\n",
    "\n",
    "# Make sure to save your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "# Instantiate the OpenAI model\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0.9)\n",
    "\n",
    "# Create an LLMChain using the knowledge triple extraction prompt\n",
    "chain = LLMChain(llm=llm, prompt=KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT)\n",
    "\n",
    "# Run the chain with the specified text\n",
    "text = \"The city of Paris is the capital and most populous city of France. The Eiffel Tower is a famous landmark in Paris.\"\n",
    "triples = chain.run(text)\n",
    "\n",
    "print(triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb65171",
   "metadata": {},
   "source": [
    "In the previous code, we used the prompt to extract relation triplets from text using few-shot examples. We'll then parse the generated triplets and collect them into a list.\n",
    "\n",
    "Here, triples_response will contain the knowledge triplets extracted from the text. We need to parse the response and collect the triplets into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4540b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_triples(response, delimiter=KG_TRIPLE_DELIMITER):\n",
    "    if not response:\n",
    "        return []\n",
    "    return response.split(delimiter)\n",
    "\n",
    "triples_list = parse_triples(triples)\n",
    "\n",
    "# Print the extracted relation triplets\n",
    "print(triples_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e57f19",
   "metadata": {},
   "source": [
    "## Knowledge Graph Visualization\n",
    "The NetworkX library is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks. It provides various graph generators, random graphs, and synthetic networks, along with the benefits of Python's fast prototyping, ease of teaching, and multi-platform support.\n",
    "\n",
    "To visualize the extracted triplets as a knowledge graph, we’ll be using the pyvis library; To install the library, execute the following command. While it is preferable to install the latest version of the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907abda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis import network\n",
    "import networkx as nx\n",
    "\n",
    "# Create a NetworkX graph from the extracted relation triplets\n",
    "def create_graph_from_triplets(triplets):\n",
    "    G = nx.DiGraph()\n",
    "    for triplet in triplets:\n",
    "        subject, predicate, obj = triplet.strip().split(',')\n",
    "        G.add_edge(subject.strip(), obj.strip(), label=predicate.strip())\n",
    "    return G\n",
    "\n",
    "# Convert the NetworkX graph to a PyVis network\n",
    "def nx_to_pyvis(networkx_graph):\n",
    "    pyvis_graph = Network(notebook=True)\n",
    "    for node in networkx_graph.nodes():\n",
    "        pyvis_graph.add_node(node)\n",
    "    for edge in networkx_graph.edges(data=True):\n",
    "        pyvis_graph.add_edge(edge[0], edge[1], label=edge[2][\"label\"])\n",
    "    return pyvis_graph\n",
    "\n",
    "triplets = [t.strip() for t in triples_list if t.strip()]\n",
    "graph = create_graph_from_triplets(triplets)\n",
    "pyvis_network = nx_to_pyvis(graph)\n",
    "\n",
    "# Customize the appearance of the graph\n",
    "pyvis_network.toggle_hide_edges_on_drag(True)\n",
    "pyvis_network.toggle_physics(False)\n",
    "pyvis_network.set_edge_smooth('discrete')\n",
    "\n",
    "# Show the interactive knowledge graph visualization\n",
    "pyvis_network.show('knowledge_graph.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91f22e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
